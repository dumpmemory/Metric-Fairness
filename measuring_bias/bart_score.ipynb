{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-03-24T00:35:41.419453Z","iopub.status.busy":"2022-03-24T00:35:41.419048Z","iopub.status.idle":"2022-03-24T00:35:43.261360Z","shell.execute_reply":"2022-03-24T00:35:43.260627Z","shell.execute_reply.started":"2022-03-24T00:35:41.419343Z"},"trusted":true},"outputs":[],"source":["# %%\n","import torch\n","import torch.nn as nn\n","import traceback\n","from transformers import BartTokenizer, BartForConditionalGeneration\n","from typing import List\n","import numpy as np\n","\n","\n","class BARTScorer:\n","    def __init__(self, device='cuda:0', max_length=1024, checkpoint='facebook/bart-large-cnn'):\n","        # Set up model\n","        self.device = device\n","        self.max_length = max_length\n","        self.tokenizer = BartTokenizer.from_pretrained(checkpoint)\n","        self.model = BartForConditionalGeneration.from_pretrained(checkpoint)\n","        self.model.eval()\n","        self.model.to(device)\n","\n","        # Set up loss\n","        self.loss_fct = nn.NLLLoss(reduction='none', ignore_index=self.model.config.pad_token_id)\n","        self.lsm = nn.LogSoftmax(dim=1)\n","\n","    def load(self, path=None):\n","        \"\"\" Load model from paraphrase finetuning \"\"\"\n","        if path is None:\n","            path = 'models/bart.pth'\n","        self.model.load_state_dict(torch.load(path, map_location=self.device))\n","\n","    def score(self, srcs, tgts, batch_size=4):\n","        \"\"\" Score a batch of examples \"\"\"\n","        score_list = []\n","        for i in range(0, len(srcs), batch_size):\n","            src_list = srcs[i: i + batch_size]\n","            tgt_list = tgts[i: i + batch_size]\n","            try:\n","                with torch.no_grad():\n","                    encoded_src = self.tokenizer(\n","                        src_list,\n","                        max_length=self.max_length,\n","                        truncation=True,\n","                        padding=True,\n","                        return_tensors='pt'\n","                    )\n","                    encoded_tgt = self.tokenizer(\n","                        tgt_list,\n","                        max_length=self.max_length,\n","                        truncation=True,\n","                        padding=True,\n","                        return_tensors='pt'\n","                    )\n","                    src_tokens = encoded_src['input_ids'].to(self.device)\n","                    src_mask = encoded_src['attention_mask'].to(self.device)\n","\n","                    tgt_tokens = encoded_tgt['input_ids'].to(self.device)\n","                    tgt_mask = encoded_tgt['attention_mask']\n","                    tgt_len = tgt_mask.sum(dim=1).to(self.device)\n","\n","                    output = self.model(\n","                        input_ids=src_tokens,\n","                        attention_mask=src_mask,\n","                        labels=tgt_tokens\n","                    )\n","                    logits = output.logits.view(-1, self.model.config.vocab_size)\n","                    loss = self.loss_fct(self.lsm(logits), tgt_tokens.view(-1))\n","                    loss = loss.view(tgt_tokens.shape[0], -1)\n","                    loss = loss.sum(dim=1) / tgt_len\n","                    curr_score_list = [-x.item() for x in loss]\n","                    score_list += curr_score_list\n","\n","            except RuntimeError:\n","                traceback.print_exc()\n","                print(f'source: {src_list}')\n","                print(f'target: {tgt_list}')\n","                exit(0)\n","        return score_list\n","\n","    def multi_ref_score(self, srcs, tgts: List[List[str]], agg=\"mean\", batch_size=4):\n","        # Assert we have the same number of references\n","        ref_nums = [len(x) for x in tgts]\n","        if len(set(ref_nums)) > 1:\n","            raise Exception(\"You have different number of references per test sample.\")\n","\n","        ref_num = len(tgts[0])\n","        score_matrix = []\n","        for i in range(ref_num):\n","            curr_tgts = [x[i] for x in tgts]\n","            scores = self.score(srcs, curr_tgts, batch_size)\n","            score_matrix.append(scores)\n","        if agg == \"mean\":\n","            score_list = np.mean(score_matrix, axis=0)\n","        elif agg == \"max\":\n","            score_list = np.max(score_matrix, axis=0)\n","        else:\n","            raise NotImplementedError\n","        return list(score_list)\n","\n","    def test(self, batch_size=3):\n","        \"\"\" Test \"\"\"\n","        src_list = [\n","            'This is a very good idea. Although simple, but very insightful.',\n","            'Can I take a look?',\n","            'Do not trust him, he is a liar.'\n","        ]\n","\n","        tgt_list = [\n","            \"That's stupid.\",\n","            \"What's the problem?\",\n","            'He is trustworthy.'\n","        ]\n","\n","        print(self.score(src_list, tgt_list, batch_size))\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T00:44:24.394478Z","iopub.status.busy":"2022-03-24T00:44:24.394215Z","iopub.status.idle":"2022-03-24T00:46:25.400867Z","shell.execute_reply":"2022-03-24T00:46:25.400009Z","shell.execute_reply.started":"2022-03-24T00:44:24.394452Z"},"trusted":true},"outputs":[],"source":["bart_scorer = BARTScorer(device='cuda:0', checkpoint='facebook/bart-base')\n","dataset_list=['race-bias','bertscore','religionbias','physical-bias','agebias','disabilitybias','socioeconomicbias']\n","with open('./avg.txt', 'w') as f1:\n","    for path in dataset_list:\n","   \n","        with open('../input/'+path + \"/hyps.txt\") as f:\n","            cands = [line.strip() for line in f]\n","\n","        with open('../input/'+path + \"/refs.txt\") as f:\n","            refs = [line.strip() for line in f]\n","        lis = bart_scorer.score(cands, refs, batch_size=4)\n","        with open('./' + path+'.txt','w') as f:\n","            for i in lis:\n","                f.write(str(i))\n","                f.write('\\n')\n","        data = []\n","        with open('./' + path+'.txt', 'r') as f:\n","            lines = f.readlines()\n","            for line in lines:\n","                l = float(line.strip())\n","                data.append(l)\n","\n","        max_value = max(data)\n","        min_value = min(data)\n","        normalized_data = []\n","        for x in data:\n","            tmp = (x - min_value) / (max_value - min_value) * 100\n","            normalized_data.append(tmp)\n","\n","        import math\n","        avg_delta = []\n","        tmp = None\n","        for x in normalized_data:\n","            if tmp is None:\n","                tmp = x\n","            else:\n","                tmp = math.fabs(tmp - x)\n","                avg_delta.append(tmp)\n","                tmp = None\n","\n","        f1.write(str(sum(avg_delta) / len(avg_delta)))\n","        f1.write('\\n')\n","\n","    \n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
